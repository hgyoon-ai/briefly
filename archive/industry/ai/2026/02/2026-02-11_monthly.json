{
  "range": {
    "from": "2026-01-13",
    "to": "2026-02-11"
  },
  "kpis": {
    "collected": 48,
    "deduped": 48,
    "uniqueTopics": 49,
    "marketShare": {
      "Tooling": 25,
      "Infra": 22,
      "Product": 22,
      "Models": 17,
      "Data": 13,
      "Other": 1
    }
  },
  "weeklyData": [
    {
      "week": "Week 1 (01/13-01/19)",
      "topicCounts": {
        "Tooling": 0,
        "Infra": 0,
        "Product": 0,
        "Models": 0,
        "Data": 0
      }
    },
    {
      "week": "Week 2 (01/20-01/26)",
      "topicCounts": {
        "Tooling": 0,
        "Infra": 0,
        "Product": 0,
        "Models": 0,
        "Data": 0
      }
    },
    {
      "week": "Week 3 (01/27-02/02)",
      "topicCounts": {
        "Tooling": 9,
        "Infra": 7,
        "Product": 7,
        "Models": 7,
        "Data": 5
      }
    },
    {
      "week": "Week 4 (02/03-02/09)",
      "topicCounts": {
        "Tooling": 12,
        "Infra": 9,
        "Product": 11,
        "Models": 10,
        "Data": 5
      }
    },
    {
      "week": "Week 5 (02/10-02/11)",
      "topicCounts": {
        "Tooling": 1,
        "Infra": 2,
        "Product": 0,
        "Models": 0,
        "Data": 2
      }
    }
  ],
  "topIssues": [
    {
      "id": 1,
      "status": "ONGOING",
      "title": "대규모 멀티모달 로봇 학습을 위한 NVIDIA Isaac Lab R²D²",
      "summary": "R²D²는 시뮬레이션·도메인 랜덤화·분산 훈련을 결합해 물리 실험 없이도 대규모 멀티모달 로봇 학습을 가능하게 하는 플랫폼으로, 로봇 AI 개발의 비용·속도 문제를 구조적으로 완화하는 추세를 보여준다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "R²D²: Scaling Multimodal Robot Learning with NVIDIA Isaac Lab",
          "url": "https://developer.nvidia.com/blog/r2d2-scaling-multimodal-robot-learning-with-nvidia-isaac-lab/"
        }
      ]
    },
    {
      "id": 2,
      "status": "ONGOING",
      "title": "가속 컴퓨팅을 활용한 대형 과학 실험 실시간 제어",
      "summary": "GPU 기반 가속 컴퓨팅을 이용해 대형 연구시설의 실험 데이터를 실시간 수집·분석하고, 그 결과를 즉시 실험 조건에 반영하는 라이브 스티어링 방식이 확산되며 과학 연구 워크플로의 지능형 자동화가 진전되고 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Using Accelerated Computing to Live-Steer Scientific Experiments at Massive Research Facilities",
          "url": "https://developer.nvidia.com/blog/using-accelerated-computing-to-live-steer-scientific-experiments-at-massive-research-facilities/"
        }
      ]
    },
    {
      "id": 3,
      "status": "NEW",
      "title": "TensorRT LLM AutoDeploy로 LLM 추론 최적화 자동화",
      "summary": "TensorRT LLM AutoDeploy는 새 아키텍처 변환, 커널 튜닝, 양자화를 자동으로 적용해 LLM 추론의 지연시간과 처리량을 개선하며, 복잡한 성능 튜닝을 플랫폼 수준에서 해결하려는 인프라 자동화 흐름을 보여준다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Automating Inference Optimizations with NVIDIA TensorRT LLM AutoDeploy",
          "url": "https://developer.nvidia.com/blog/automating-inference-optimizations-with-nvidia-tensorrt-llm-autodeploy/"
        }
      ]
    },
    {
      "id": 4,
      "status": "NEW",
      "title": "NVFP4 초저정밀 포맷으로 AI 학습·추론 효율 향상",
      "summary": "NVFP4는 초저정밀 부동소수점 포맷과 전용 하드웨어·소프트웨어 최적화를 통해 연산 처리량을 높이고 메모리·대역폭 사용을 줄여, 대규모 모델의 학습·추론 비용을 낮추는 정밀도 혁신 흐름을 대표한다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "3 Ways NVFP4 Accelerates AI Training and Inference",
          "url": "https://developer.nvidia.com/blog/3-ways-nvfp4-accelerates-ai-training-and-inference/"
        }
      ]
    },
    {
      "id": 5,
      "status": "NEW",
      "title": "Kubernetes에서 시간 기반 페어셰어로 GPU 자원 공정 배분",
      "summary": "NVIDIA Run:ai v2.24의 시간 기반 페어셰어 모드는 할당량 초과 GPU 사용에 시간 가중치를 적용해, 다수 팀·워크로드가 공유하는 Kubernetes 클러스터에서 GPU 자원을 보다 예측 가능하고 공정하게 배분하도록 돕는다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Ensuring Balanced GPU Allocation in Kubernetes Clusters with Time-Based Fairshare",
          "url": "https://developer.nvidia.com/blog/ensuring-balanced-gpu-allocation-in-kubernetes-clusters-with-time-based-fairshare/"
        }
      ]
    }
  ]
}