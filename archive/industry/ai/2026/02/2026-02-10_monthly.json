{
  "range": {
    "from": "2026-01-12",
    "to": "2026-02-10"
  },
  "kpis": {
    "collected": 46,
    "deduped": 46,
    "uniqueTopics": 49,
    "marketShare": {
      "Tooling": 25,
      "Product": 23,
      "Infra": 21,
      "Models": 18,
      "Research": 12,
      "Other": 1
    }
  },
  "weeklyData": [
    {
      "week": "Week 1 (01/12-01/18)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    },
    {
      "week": "Week 2 (01/19-01/25)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    },
    {
      "week": "Week 3 (01/26-02/01)",
      "topicCounts": {
        "Tooling": 9,
        "Product": 7,
        "Infra": 7,
        "Models": 7,
        "Research": 6
      }
    },
    {
      "week": "Week 4 (02/02-02/08)",
      "topicCounts": {
        "Tooling": 13,
        "Product": 12,
        "Infra": 11,
        "Models": 11,
        "Research": 6
      }
    },
    {
      "week": "Week 5 (02/09-02/10)",
      "topicCounts": {
        "Tooling": 3,
        "Product": 4,
        "Infra": 3,
        "Models": 0,
        "Research": 0
      }
    }
  ],
  "topIssues": [
    {
      "id": 1,
      "status": "NEW",
      "title": "TensorRT LLM AutoDeploy로 LLM 추론 최적화 자동화",
      "summary": "NVIDIA TensorRT LLM AutoDeploy가 모델 아키텍처 변환, 커널 튜닝, 양자화를 자동 처리해 LLM 추론의 지연시간을 줄이고 처리량을 높이는 배포·최적화 파이프라인을 제공한다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Automating Inference Optimizations with NVIDIA TensorRT LLM AutoDeploy",
          "url": "https://developer.nvidia.com/blog/automating-inference-optimizations-with-nvidia-tensorrt-llm-autodeploy/"
        }
      ]
    },
    {
      "id": 2,
      "status": "NEW",
      "title": "GenAI.mil에 특화된 군사용 ChatGPT 배포",
      "summary": "OpenAI for Government가 미 국방 분야 전용 GenAI.mil 환경에 맞춤형 ChatGPT를 배포해, 보안과 안전성을 강화한 형태로 군 조직이 최신 생성형 AI에 접근할 수 있도록 했다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Bringing ChatGPT to GenAI.mil",
          "url": "https://openai.com/index/bringing-chatgpt-to-genaimil"
        }
      ]
    },
    {
      "id": 3,
      "status": "NEW",
      "title": "Transformers.js v4 프리뷰: 브라우저·Node 추론 성능 개선",
      "summary": "Hugging Face의 Transformers.js v4 프리뷰가 NPM에 공개되어 브라우저와 Node 환경에서의 모델 추론 성능, 호환성, 개발자 사용성을 전반적으로 개선하는 업데이트를 제공한다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "Hugging Face Blog",
          "title": "Transformers.js v4 Preview: Now Available on NPM!",
          "url": "https://huggingface.co/blog/transformersjs-v4"
        }
      ]
    },
    {
      "id": 4,
      "status": "NEW",
      "title": "NVFP4: 초저정밀 포맷으로 AI 학습·추론 가속",
      "summary": "NVIDIA의 NVFP4 포맷은 초저정밀 부동소수점 연산과 전용 하드웨어·소프트웨어 최적화를 통해 연산 처리량을 높이고 메모리·대역폭 사용을 줄이며, 기존 ML 프레임워크와 통합해 학습과 추론 속도를 동시에 향상한다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "3 Ways NVFP4 Accelerates AI Training and Inference",
          "url": "https://developer.nvidia.com/blog/3-ways-nvfp4-accelerates-ai-training-and-inference/"
        }
      ]
    },
    {
      "id": 5,
      "status": "ONGOING",
      "title": "글로벌 AI 모델의 지역화 전략과 안전성 유지",
      "summary": "OpenAI는 언어·법·문화가 다른 각 지역에 맞게 모델을 조정하면서도, 접근성·규제 준수·문화적 적합성과 동시에 안전성을 유지하는 지역화 프레임워크를 지속적으로 발전시키고 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Making AI work for everyone, everywhere: our approach to localization",
          "url": "https://openai.com/index/our-approach-to-localization"
        }
      ]
    }
  ]
}