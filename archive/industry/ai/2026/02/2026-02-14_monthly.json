{
  "range": {
    "from": "2026-01-16",
    "to": "2026-02-14"
  },
  "kpis": {
    "collected": 56,
    "deduped": 56,
    "uniqueTopics": 49,
    "marketShare": {
      "Tooling": 24,
      "Product": 24,
      "Infra": 20,
      "Models": 19,
      "Research": 14,
      "Other": 0
    }
  },
  "weeklyData": [
    {
      "week": "Week 1 (01/16-01/22)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    },
    {
      "week": "Week 2 (01/23-01/29)",
      "topicCounts": {
        "Tooling": 5,
        "Product": 5,
        "Infra": 4,
        "Models": 3,
        "Research": 4
      }
    },
    {
      "week": "Week 3 (01/30-02/05)",
      "topicCounts": {
        "Tooling": 10,
        "Product": 6,
        "Infra": 9,
        "Models": 7,
        "Research": 3
      }
    },
    {
      "week": "Week 4 (02/06-02/12)",
      "topicCounts": {
        "Tooling": 6,
        "Product": 8,
        "Infra": 6,
        "Models": 2,
        "Research": 2
      }
    },
    {
      "week": "Week 5 (02/13-02/14)",
      "topicCounts": {
        "Tooling": 2,
        "Product": 2,
        "Infra": 0,
        "Models": 2,
        "Research": 1
      }
    }
  ],
  "topIssues": [
    {
      "id": "ai-1",
      "status": "NEW",
      "title": "GPT-5.2, 이론물리에서 새로운 글루온 진폭 수식 제안·검증",
      "summary": "GPT-5.2가 제안한 글루온 진폭에 대한 새로운 수식이 사전 공개 후 학계와 OpenAI의 협력으로 형식적으로 증명·검증되었다. 대형 언어모델이 기존 지식을 요약하는 수준을 넘어, 이론물리 같은 첨단 기초과학 분야에서 실제로 새로운 공식을 도출하고 학술적 검증을 통과한 사례라는 점에서 AI 연구 패러다임 전환의 신호탄으로 평가된다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "GPT-5.2 derives a new result in theoretical physics",
          "url": "https://openai.com/index/new-result-theoretical-physics"
        }
      ]
    },
    {
      "id": "ai-2",
      "status": "NEW",
      "title": "ChatGPT ‘Lockdown Mode’와 위험 레이블로 프롬프트 인젝션 방어 강화",
      "summary": "OpenAI가 조직용 ChatGPT에 Lockdown Mode와 Elevated Risk 레이블을 도입해 프롬프트 인젝션과 AI 기반 데이터 유출에 대한 방어를 크게 강화했다. Lockdown Mode는 모델이 외부 도구·데이터에 접근하는 경로를 제한하고, Elevated Risk 레이블은 고위험 상호작용을 명시적으로 표시해 보안팀과 운영자가 민감한 업무 환경에서 AI를 더 안전하게 활용할 수 있도록 돕는다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
          "url": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt"
        }
      ]
    },
    {
      "id": "ai-3",
      "status": "ONGOING",
      "title": "OpenEnv로 실제 환경에서 도구 사용 에이전트 성능 체계적 평가",
      "summary": "Hugging Face의 OpenEnv 프로젝트가 실제 환경과 다양한 도구 통합을 통해 에이전트의 도구 사용 능력을 정량적으로 평가하는 프레임워크로 발전하고 있다. 재현 가능한 벤치마크, 표준화된 평가 지표, 대표적인 오류 모드 분석을 제공해, 연구자와 개발자가 에이전트 기반 애플리케이션의 신뢰성과 안전성을 비교·개선하는 데 활용할 수 있는 인프라로 자리잡는 중이다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "Hugging Face Blog",
          "title": "OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments",
          "url": "https://huggingface.co/blog/openenv-turing"
        }
      ]
    },
    {
      "id": "ai-4",
      "status": "ONGOING",
      "title": "가속화 컴퓨팅으로 대형 과학 실험을 실시간 최적화하는 AI 워크플로",
      "summary": "NVIDIA는 GPU 기반 가속화 컴퓨팅을 활용해 대형 연구시설에서 발생하는 막대한 데이터를 실시간 수집·분석·피드백해 실험 조건을 즉시 조정하는 ‘라이브 스티어링’ 기법을 소개했다. 이 접근법은 AI 기반 분석과 고성능 컴퓨팅 인프라를 결합해 물리·재료·생명과학 등 분야의 실험 효율과 정밀도를 높이고, 한정된 빔타임·장비 자원을 최대한 활용하도록 돕는다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Using Accelerated Computing to Live-Steer Scientific Experiments at Massive Research Facilities",
          "url": "https://developer.nvidia.com/blog/using-accelerated-computing-to-live-steer-scientific-experiments-at-massive-research-facilities/"
        }
      ]
    },
    {
      "id": "ai-5",
      "status": "NEW",
      "title": "TensorRT LLM AutoDeploy로 LLM 추론 최적화 전 과정을 자동화",
      "summary": "NVIDIA TensorRT LLM AutoDeploy는 새 모델 아키텍처 변환, 커널 튜닝, 양자화 등 복잡한 추론 최적화 단계를 자동 처리해 지연시간을 줄이고 처리량을 높인다. AI 서비스 운영팀은 수동 성능 튜닝 부담을 줄이고, 다양한 하드웨어 환경에서 일관된 고성능 LLM 추론을 보다 빠르게 배포·갱신할 수 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Automating Inference Optimizations with NVIDIA TensorRT LLM AutoDeploy",
          "url": "https://developer.nvidia.com/blog/automating-inference-optimizations-with-nvidia-tensorrt-llm-autodeploy/"
        }
      ]
    }
  ]
}