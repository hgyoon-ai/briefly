{
  "range": {
    "from": "2026-01-11",
    "to": "2026-02-09"
  },
  "kpis": {
    "collected": 42,
    "deduped": 42,
    "uniqueTopics": 49,
    "marketShare": {
      "Tooling": 25,
      "Product": 21,
      "Infra": 20,
      "Models": 20,
      "Research": 13,
      "Other": 1
    }
  },
  "weeklyData": [
    {
      "week": "Week 1 (01/11-01/17)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    },
    {
      "week": "Week 2 (01/18-01/24)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    },
    {
      "week": "Week 3 (01/25-01/31)",
      "topicCounts": {
        "Tooling": 9,
        "Product": 7,
        "Infra": 7,
        "Models": 7,
        "Research": 6
      }
    },
    {
      "week": "Week 4 (02/01-02/07)",
      "topicCounts": {
        "Tooling": 13,
        "Product": 12,
        "Infra": 11,
        "Models": 11,
        "Research": 6
      }
    },
    {
      "week": "Week 5 (02/08-02/09)",
      "topicCounts": {
        "Tooling": 0,
        "Product": 0,
        "Infra": 0,
        "Models": 0,
        "Research": 0
      }
    }
  ],
  "topIssues": [
    {
      "id": 1,
      "status": "NEW",
      "title": "초저정밀 포맷 NVFP4로 AI 학습·추론 가속",
      "summary": "NVIDIA의 NVFP4 초저정밀 부동소수점 포맷이 연산 처리량을 높이고 메모리·대역폭 사용을 줄여 AI 모델 학습과 추론 성능을 크게 개선한다. 기존 ML 프레임워크와 통합이 용이해 최신 하드웨어 성능을 바로 활용할 수 있는 점이 핵심이다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "3 Ways NVFP4 Accelerates AI Training and Inference",
          "url": "https://developer.nvidia.com/blog/3-ways-nvfp4-accelerates-ai-training-and-inference/"
        }
      ]
    },
    {
      "id": 2,
      "status": "ONGOING",
      "title": "글로벌 AI 모델의 지역화 전략과 안전성",
      "summary": "OpenAI는 하나의 최첨단 글로벌 모델을 각 지역의 언어, 규제, 문화에 맞게 조정하는 지역화 전략을 제시한다. 접근성과 규제 준수, 문화적 적합성을 확보하면서도 모델 안전성 기준을 유지하는 프레임워크 구축에 초점을 두고 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Making AI work for everyone, everywhere: our approach to localization",
          "url": "https://openai.com/index/our-approach-to-localization"
        }
      ]
    },
    {
      "id": 3,
      "status": "NEW",
      "title": "한국 전용 개인정보 처리방침으로 본 AI 서비스 현지 규제 대응",
      "summary": "OpenAI가 한국 전용 개인정보 처리방침을 마련해 국내 법규에 따른 데이터 처리, 보관, 이용자 권리 보장을 명문화했다. 글로벌 AI 서비스가 각국 프라이버시 규제에 맞춰 세분화된 정책을 도입하는 흐름을 보여준다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Korea privacy policy",
          "url": "https://openai.com/policies/kr-privacy-policy"
        }
      ]
    },
    {
      "id": 4,
      "status": "ONGOING",
      "title": "생성형 AI를 활용한 게임 자산 대규모 현대화",
      "summary": "Painkiller RTX 사례에서 보듯, 생성형 AI를 활용한 업스케일링과 자동 텍스처 생성이 소규모 팀도 방대한 게임 자산을 현대화할 수 있게 만든다. 이는 게임 개발 파이프라인의 효율화와 시각적 품질 향상을 동시에 추구하는 방향을 보여준다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "How Painkiller RTX Uses Generative AI to Modernize Game Assets at Scale",
          "url": "https://developer.nvidia.com/blog/how-painkiller-rtx-uses-generative-ai-to-modernize-game-assets-at-scale/"
        }
      ]
    },
    {
      "id": 5,
      "status": "NEW",
      "title": "Nemotron 기반 RAG 문서 처리 파이프라인 고도화",
      "summary": "NVIDIA는 Nemotron을 활용해 복잡한 PDF, 중첩 표, 차트 데이터 등 비정형·구조화 문서를 RAG에 최적화된 형태로 전처리하는 파이프라인 설계 방법을 제안했다. 이는 기업 문서 기반 AI 검색·질의응답 시스템의 정확도와 활용성을 높이는 기반 기술로 볼 수 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "How to Build a Document Processing Pipeline for RAG with Nemotron",
          "url": "https://developer.nvidia.com/blog/how-to-build-a-document-processing-pipeline-for-rag-with-nemotron/"
        }
      ]
    }
  ]
}