{
  "range": {
    "from": "2026-01-29",
    "to": "2026-02-27"
  },
  "kpis": {
    "collected": 64,
    "deduped": 64,
    "uniqueTopics": 10,
    "marketShare": {
      "Tooling": 25,
      "Product": 21,
      "Models": 20,
      "Infra": 20,
      "Research": 14,
      "Other": 0
    }
  },
  "weeklyData": [
    {
      "week": "Week 1 (01/29-02/04)",
      "topicCounts": {
        "Tooling": 8,
        "Product": 5,
        "Models": 8,
        "Infra": 7,
        "Research": 4
      }
    },
    {
      "week": "Week 2 (02/05-02/11)",
      "topicCounts": {
        "Tooling": 9,
        "Product": 10,
        "Models": 5,
        "Infra": 9,
        "Research": 4
      }
    },
    {
      "week": "Week 3 (02/12-02/18)",
      "topicCounts": {
        "Tooling": 4,
        "Product": 4,
        "Models": 5,
        "Infra": 1,
        "Research": 4
      }
    },
    {
      "week": "Week 4 (02/19-02/25)",
      "topicCounts": {
        "Tooling": 9,
        "Product": 5,
        "Models": 5,
        "Infra": 7,
        "Research": 4
      }
    },
    {
      "week": "Week 5 (02/26-02/27)",
      "topicCounts": {
        "Tooling": 2,
        "Product": 4,
        "Models": 4,
        "Infra": 1,
        "Research": 4
      }
    }
  ],
  "topIssues": [
    {
      "id": 1,
      "status": "NEW",
      "title": "실제 업무용 AI 에이전트 연구 가속(CORPGEN)",
      "summary": "Microsoft Research의 CORPGEN 프로젝트는 보고서 작성, 스프레드시트, 슬라이드, 이메일 등 상호 의존적인 오피스 업무를 하나의 AI 에이전트가 처리하도록 설계·평가하는 프레임워크를 제시한다. 지식 노동자의 실제 워크플로를 정교하게 모사해, 실무 투입 가능한 에이전트 기반 업무 자동화·지원 기술을 본격적으로 실험하는 단계에 들어섰다는 점에서 주간·월간 업데이트의 핵심 이슈다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "Microsoft Research Blog",
          "title": "CORPGEN advances AI agents for real work",
          "url": "https://www.microsoft.com/en-us/research/blog/corpgen-advances-ai-agents-for-real-work/"
        }
      ]
    },
    {
      "id": 2,
      "status": "NEW",
      "title": "차세대 초고속 이미지 생성 모델 Nano Banana 2 공개",
      "summary": "Google DeepMind의 Nano Banana 2는 고급 세계 지식과 높은 주제 일관성을 갖추면서도 Flash 추론으로 실시간 서비스에 적합한 초고속 이미지 생성 모델이다. 프로급 이미지 품질을 유지하면서 추론 지연을 크게 줄여, 대규모 상용 서비스와 인터랙티브 애플리케이션에서 생성형 비전 모델 활용 폭을 넓힐 핵심 업데이트로 볼 수 있다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "Google DeepMind Blog",
          "title": "Nano Banana 2: Combining Pro capabilities with lightning-fast speed",
          "url": "https://deepmind.google/blog/nano-banana-2-combining-pro-capabilities-with-lightning-fast-speed/"
        }
      ]
    },
    {
      "id": 3,
      "status": "NEW",
      "title": "연방 인허가 업무 가속을 위한 OpenAI–PNNL 협력",
      "summary": "OpenAI와 Pacific Northwest National Laboratory가 NEPA 문서 초안 작성을 위한 DraftNEPABench 벤치마크를 발표했다. 이는 코딩·도큐멘트 에이전트를 활용해 연방 인허가 절차의 문서 작업 시간을 최대 15%까지 단축할 수 있는지를 평가하는 기준으로, 공공 부문 행정과 규제 프로세스에 AI를 본격 도입하기 위한 인프라 구축 단계라는 점에서 중요한 정책·실무 이슈다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "OpenAI Blog",
          "title": "Pacific Northwest National Laboratory and OpenAI partner to accelerate federal permitting",
          "url": "https://openai.com/index/pacific-northwest-national-laboratory"
        }
      ]
    },
    {
      "id": 4,
      "status": "ONGOING",
      "title": "NVIDIA Blackwell Ultra 기반 LLM 소프트맥스 최적화",
      "summary": "NVIDIA는 Blackwell Ultra 아키텍처에서 소프트맥스 연산을 최적화해, 초장문 컨텍스트와 MLA·Grouped Query 등 복잡한 어텐션 구조를 가진 LLM의 추론 효율을 높이는 기법을 소개했다. 이는 점점 길어지는 프롬프트와 멀티모달 입력을 감당하기 위한 하드웨어·커널 수준 최적화의 연속적인 흐름으로, 대규모 AI 서비스의 비용·지연 시간 개선을 위한 상시 진행 이슈다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Making Softmax More Efficient with NVIDIA Blackwell Ultra",
          "url": "https://developer.nvidia.com/blog/making-softmax-more-efficient-with-nvidia-blackwell-ultra/"
        }
      ]
    },
    {
      "id": 5,
      "status": "NEW",
      "title": "NVFP4 저정밀 학습으로 처리량 극대화",
      "summary": "NVIDIA는 NVFP4라는 새로운 4비트 저정밀 수치 포맷을 도입해, BF16 대비 더 높은 처리량과 메모리 효율을 유지하면서도 학습 정확도 손실을 최소화하는 방법을 제시했다. 초대형 모델 학습 비용과 자원 사용량을 줄이기 위한 핵심 기술로, 장기적으로는 더 큰 모델과 더 긴 컨텍스트를 경제적으로 학습·서빙하게 만드는 인프라 측 업데이트다.",
      "articleCount": 1,
      "relatedArticles": [
        {
          "source": "NVIDIA Developer Blog",
          "title": "Using NVFP4 Low-Precision Model Training for Higher Throughput Without Losing Accuracy",
          "url": "https://developer.nvidia.com/blog/using-nvfp4-low-precision-model-training-for-higher-throughput-without-losing-accuracy/"
        }
      ]
    }
  ]
}