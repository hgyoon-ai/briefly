name: Crawl and update data

on:
  schedule:
    - cron: "0 22 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check OpenAI connection
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MY_GITHUB_TOKEN: ${{ secrets.MY_GITHUB_TOKEN }}
        run: python3 -m scripts.check_openai_connection

  crawl:
    needs: check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run pipeline
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          MY_GITHUB_TOKEN: ${{ secrets.MY_GITHUB_TOKEN }}
        run: python3 -m scripts.run_pipeline

      - name: Commit updates
        run: |
          git status --porcelain
          if [ -n "$(git status --porcelain)" ]; then
            git add public/latest archive
            git -c user.name="github-actions[bot]" -c user.email="github-actions[bot]@users.noreply.github.com" commit -m "Update crawl data $(date +'%Y-%m-%d')"
            git push
          fi
