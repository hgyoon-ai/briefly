name: Crawl briefing

on:
  schedule:
    - cron: "0 22 * * *"
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: data-pipelines-${{ github.ref }}
  cancel-in-progress: false

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check OpenAI connection
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python3 -m scripts.check_openai_connection

  briefing:
    needs: check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run briefing pipeline
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python3 -m scripts.run_briefing_pipeline

      - name: Commit updates
        run: |
          git status --porcelain
          if [ -n "$(git status --porcelain)" ]; then
            git add public/briefing archive
            git -c user.name="github-actions[bot]" -c user.email="github-actions[bot]@users.noreply.github.com" commit -m "Update briefing data $(date +'%Y-%m-%d')"
            for attempt in 1 2 3; do
              git fetch origin main
              if git pull --rebase origin main && git push; then
                break
              fi
              echo "Push failed (attempt $attempt/3); retrying..."
              sleep $((attempt * 5))
            done
          fi
